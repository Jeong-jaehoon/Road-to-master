{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1장 한눈에 보는 머신러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 준지도학습\n",
    "ex) 구글 포토 호스팅 서비스  \n",
    "소수의 레이블로 편리하게 사진을 찾을 수 있음  \n",
    "대부분의 준지도 학습 알고리즘은 지도 학습과 비지도 학습의 조화로 이루어져 있다.  \n",
    "`심층 신뢰 신경망` - DBN(deep belief network)는 여러 겹으로 쌓은 `제한된 볼츠만 머신` - RBM(Restricted Boltzmann machine)이라고 불리는 비지도 학습에 기초한다  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 강화학습\n",
    "강화학습은 다른 알고리즘들과는 매우 다른 종류의 알고리즘이다. 여기서 학습 하는 시스템을 `에이전트`라고 부르며 `환경`을 관찰해서 `행동`을 실행하고 그 결과로 `보상`과 `벌점`을 받는다. 시간이 지나면서 가장 큰 `보상`을 얻기 위해 `정책(policy)`라고 부르는 최상의 전략을 스스로 학습한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배치 학습(batch learning)\n",
    "\n",
    "배치 학습에서는 시스템이 점진적으로 학습할 수 없습니다. 가용한 데이터를 모두 사용해 훈련시켜야 합니다. 일반적으로 이 방식은 시간과 자원을 많이 소모하므로 보통 오프라인에서 수행된다. 먼저 시스템을 훈련시키고 그런 다음 제품 시스템에 적용하면 더 이상의 학습은 없습니다. 이를 `오프라인 학습`이라고 불립니다.  \n",
    "\n",
    "- 느낌 : 항상 전체 데이터로 학습하기 때문에 학습 시간, 비용이 많이 소요된다. 즉 많은 컴퓨팅 자원이 필요하다.  \n",
    "- 시스템이 빠르게 변하는 데이터(주식)에는 더 능동적인 방법이 필요하다\n",
    "- 즉 점진적으로 학습 할 수 있는 알고리즘이 필요하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 온라인 학습(점진적 학습)\n",
    "`온라인 학습`에서는 데이터를 순차적으로 한 개씩 또는 `미니배치`라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련시킨다. 매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는대로 즉시 학습할 수 있다.\n",
    "- 온라인 학습은 연속적으로 데이터를 받고(주식) 빠른 변화에 스스로 적응해야하는 시스템에 적합하다.\n",
    "- 컴퓨팅 자원이 제한된 경우에도 좋은 선택이다\n",
    "- 온라인 학습 시스템이 새로운 데이터 샘플을 학습하면 학습이 끝난 데이터는 더 이상 필요하지 않으므로 버려도된다.(예외적으로 데이터 재사용을 위해 필요하면 보관이 필요..) -> 공간 절약 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 온라인 학습 시스템에서 파라미터\n",
    "- 학습률을 높게하면 시스템이 데이터에 빠르게 적응하지만 예전 데이터를 금방 잊어버림\n",
    "- 학습률이 낮으면 시스템의 관성이 더커져 더 느리게 학습된다 대신 새로운 데이터에 있는 노이즈나 대표성이 없는 데이터 포인트에 덜 민감해진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사례 기반 학습과 모델 기반 학습\n",
    "`머신러닝 시스템은 어떻게 일반화 하냐에 따라 분류할 수도 있다. 대부분의 머신러닝 작업은 예측을 만드는 것인데 이 말은 주어진 훈련 데이터로 학습하지만 훈련데이터에서는 본적 없는 새로운 데이터로 일반화 되어야 한다는 뜻이다. 훈련데이터에서 높은 성능을 내는 것이 좋지만 그게 전부는 아니다. 진짜 목표는 새로운샘플(test data)에서 잘 작동하는 모델이어야한다는 것이다. 이 두가지 접근법은 사례기반학습과 모델기반 학습이다.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사례기반학습 - 50p 그림참조\n",
    "스펨매일과 동일한 메일을 스팸이라고 하는 대신 스팸 메일과 매우 유사한 메일을 구분하도록 프로그래밍이가능하다.  \n",
    "이렇게 하려면 `유사도(similarity)`를 측정하면 된다. 이를 `사례 기반 학습(instance-based learning)`이라고 한다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델기반학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플로부터 일반화시키는 다른 방법은 이 샘플들의 모델을 만들어 `예측`에 사용하는 것 입니다.  \n",
    "이 방법이 바로 `모델기반학습(model-based learning)`  \n",
    "모델을 만들려면 파라미터를 지정해줘야하는데 모델이 최상의 성능을 내도록 하는 값을 어떻게 알 수 있을까..?  이 질문에 대답하려면 측정지표를 정해야한다. 모델이 얼마나 좋은지 측정하는 `효용함수(utility function)`을 정의하거나 얼마나 나쁜지 측정하는 `비용함수(cost function)`을 정의하면 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝의 주요 도전 과제\n",
    "\n",
    "### 1. 충분하지 않은 양의 훈련 데이터\n",
    "대부분의 머신러닝 알고리즘이 작동하려면 수천에서 많게는 수백만 이상의 데이터가 필요하다.  \n",
    "2001년 논문에 따르면 데이터가 좋다면 어떠한 문제에 대해서 여러 다른 알고리즘이 문제를 비슷하게 잘 처리한다고 한다.  \n",
    "즉, 알고리즘 개발과, 좋은 말뭉치(corpus) 개발(데이터 개발)에 트레이드 오프가 필요하다는 것이다.  \n",
    "데이터를 수집하는건 항상 쉽거나 저렴한 일이 아니므로 아직은 알고리즘을 무시하지는 말아야한다.  \n",
    "\n",
    "### 2. 대표성이 없는 훈련 데이터\n",
    "일반화가 잘되려면 우리가 일반화 하기 원하는 새로운 사례를 훈련 데이터가 잘 대표하는 것이 중요하다. 이는 사례기반학습이나 모델기반학습 모두 동일하다.  \n",
    "일반화하려는 사례들을 대표하는 훈련세트를 사용하는 것이 매우 중요하지만, 쉽게 되지않는다.  \n",
    "샘플이 작으면 샘플링 잡음(sampling noise), 매우 큰 샘플도 표본 추출 방법이 잘못되면 대표성을 띄지 못할 수도 있다. 이를 샘플링 편향(Sampling bias)라고한다.  \n",
    "\n",
    "### 3. 낮은 품질의 데이터\n",
    "훈련 데이터가 에러, 이상치, 잡음으로 가득하다면 머신러닝 시스템이 내재된 패턴을 찾기 어려워 잘 작동하지 않을 것이다. 그렇기 때문에 훈련데이터 정제에 시간을 많이 투자할 필요가있다. \n",
    "\n",
    "### 4. 관련 없는 특성\n",
    "feature engineering에 대한 내용이며 feature engineering은 다음과 같은 작업을 포함한다.\n",
    "- feature selection\n",
    "- feature extraction : 특성을 결합하여 더 유용한 특성을 만든다 ( 예를 들면 차원 축소 알고리즘)\n",
    "- 새로운 데이터를 수집해 새 특성을 만듭니다.\n",
    "\n",
    "### 5. 훈련 데이터 과대적합(Overfitting)\n",
    "과대 적합은 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 일어난다. 해결방법은 다음과 같다\n",
    "- 파라미터 수가 적은 모델을 선택하거나(예를들면 고차원 다항 모델보다 선형모델), 훈련데이터에 있는 특성 수를 줄이거나, 모델에 제약을 가하여 단순화)\n",
    "- 훈련데이터를 더 많이 모은다.\n",
    "- 훈련 데이터의 잡음을 줄인다(예를들면 오류데이터 수정과 이상치 제거)   \n",
    "\n",
    "모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는것을 규제(regularization)이라고 한다. \n",
    "\n",
    "### 6.훈련 데이터 과소적합(Underfitting)\n",
    "모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 일어난다.  예를 들어 삶의 만족도에 대한 선형 모델은 과소적합 되기 쉽다. 이 문제를 해결하려면\n",
    "- 모델 파라미터가 더 많은 강력한 모델을 선택\n",
    "- 학습 알고리즘에 더 좋은 특성을 제공한다(특성 공학)\n",
    "- 모델의 제약을 줄인다(규제 파라미터(regularization parameter)를 감소)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트와 검증\n",
    "새로운 샘플에 대한 오류비율을 일반화오차(generalization error) \n",
    "훈련 오차가 낮지만 일반화 오차가 높다면 이는 모델이 훈련 데이터에 과대적합 됐다는 뜻..\n",
    "보통 80%의 train set, 20% test set 으로 데이터 나눔  \n",
    "일반화 오차를 테스트 세트에서 여러 번 측정했으므로 모델과 하이퍼파라미터가 테스트세트에 최적화된 모델을 만들 수 있음  \n",
    "이문제에 대한 해결 방법으로 `Validation set(검증 세트)`라고 부르는 홀드아웃 세트를 만드는 것이 있다.\n",
    "훈련 데이터에서 검증 세트로 너무 많은 양의 데이터를 뻇기지 않기 위해 일반적으로는 `교차 검증(Cross validation)`기법을 사용 훈련 세트를 서브셋의 조합으로 훈련시키고 나머지 부분으로 검증한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연습문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 머신러닝을 어떻게 정의할 수 있나요?\n",
    "- 머신러닝은 데이터로부터 학습할 수 있는 시스템을 만드는 것, 여기서 학습이란 어떤 작업에서 주어진 성능 지표(performance)가 더 나아지는것을 의미한다\n",
    "\n",
    "#### 2. 머신러닝이 도움을 줄 수 있는 문제 유형 네 가지를 말해보세요.\n",
    "- 명확한 해결책이 없는 복잡한 문제\n",
    "- 수작업으로 만든 긴 규칙 리스트를 만들어야 하는 경우\n",
    "- 변화하는 환경에 적응하는 시스템을 만드는 경우\n",
    "- 사람에게 insight를 제공해야하는 경우(data mining)\n",
    "\n",
    "#### 3. 레이블된 훈련 세트란 무엇인가요?\n",
    "- 레이블된 훈련 세트는 각 샘플에 대해 원하는 정답 레이블을 가지고있는 훈련 세트입니다.\n",
    "\n",
    "#### 4. 가장 널리 사용되는 지도 학습 작업 두 가지는 무엇인가요?\n",
    "- 회귀와 분류\n",
    "\n",
    "#### 5. 보편적인 비지도학습 작업 네 가지는 무엇인가요?\n",
    "- 군집, 시각화, 차원 축소, 연관 규칙 학습\n",
    "\n",
    "#### 6. 사전 정보가 없는 여러 지형에서 로봇을 걸어가게 하려면 여러 종류의 머신러닝 알고리즘을 사용할 수 있나요?\n",
    "- 알려지지 않은 지형을 탐험하는 로봇을 가장 잘 학습시키는 알고리즘은 강화 학습이다. \n",
    "\n",
    "#### 7. 고객을 여러 그룹으로 분할하려면 어떤 알고리즘을 사용해야 하나요?\n",
    "- 그룹을 어떻게 정의할지 모르겠다면 군집 알고리즘(비지도 학습), 레이블링이 가능하다면 분류알고리즘(지도학습)을 이용하면 된다.\n",
    "\n",
    "#### 8. 스팸 감지의 문제는 지도 학습과 비지도 학습 중 어떤 문제로 볼 수 있나요?\n",
    "- 지도학습\n",
    "\n",
    "#### 9. 온라인 학습 시스템이 무엇인가요?\n",
    "- 온라인학습시스템은 배치학습시스템과 달리 점진적인 학습을 하는 알고리즘이다. 이 방식은 변화하는 데이터와 자율 시스템에 빠르게 적응하고 매우 많은 양의 데이터를 훈련 시킬 수 있다.\n",
    "\n",
    "#### 10. 외부 메모리 학습이 무엇인가요?\n",
    "- 외부 메모리 알고리즘은 컴퓨터의 주메모리에 들어갈 수 없는 대용량의 데이터를 다룰 수 있다. 외부 메모리 학습 알고리즘은 데이터를 미니배치로 나누고 온라인 학습 기법을 이용해 학습한다.\n",
    "\n",
    "#### 11. 예측을 하기 위해 유사도 측정에 의존하는 학습 알고리즘은 무엇인가요?\n",
    "- 사례 기반학습(instance-basd learning), 새로운 학습데이터가 주어지면 유사도 측정을 이용해 학습된 샘플중에서 가장 비슷한것을 찾아 예측으로 사용.\n",
    "\n",
    "#### 12. 모델 파라미터와 학습 알고리즘의 하이퍼파라미터 사이에는 어떤 차이가 있나요?\n",
    "- 모델 파라미터는 하나이상의 파라미터를 사용해 새로운 샘플이 주어지면 무엇을 예측할지 결정한다. 학습 알고리즘은 모델이 새로운 샘플에 얼마나 일반화되도록 이런 파라미터들의 최적 값을 찾는다. 하이퍼파라미터는 모델이 아니라 이런 학습 알고리즘 자체의 파라미터이다(예를들면, 모델 규제의 정도)  \n",
    "[참고]https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/  \n",
    "<쉽게말하면 hyperparameter는 사용자 정의 parameter, model parameter는 data가 결정하는 parameter>\n",
    "\n",
    "#### 13. 모델 기반 알고리즘이 찾는 것은 무엇인가요? 성공을 위해 이 알고리즘이 사용하는 가장 일반적인 전략은 무엇인가요? 예측은 어떻게 만드나요?\n",
    "- 모델 기반 학습 알고리즘은 새로운 샘플에 가장 잘 일반화되기위한 모델 파라미터의 최적 값을 찾는다. 일반적으로 훈련데이터에서 시스템의 예측이 얼마나 나쁜지 측정하고 모델에 규제가 있다면 모델 복잡도에 대한 페널티를 더한 비용 함수를 최소화함으로써 시스템을 훈련시킨다. 예측을 만들려면 학습 알고리즘이 찾은 파라미터를 사용하는 모델의 예측 함수에 새로운 샘플의 특성을 주입한다.\n",
    "\n",
    "#### 14. 머신러닝 주요 도전과제는 무엇인가요?\n",
    "- 부족한 데이터, 낮은 데이터 품질, 대표성 없는 데이터, 무의미한 특성, Overfitting과 Underfitting\n",
    "\n",
    "#### 15. 모델이 훈련 데이터에서의 성능은 좋지만 새로운 샘플에서의 일반화 성능이 나쁘다면 어떤 문제가 있는 것인가요? 가능한 해결책 세가지는 무엇인가요?\n",
    "- 모델이 과적합되었을 가능성이 매우높다. 과적합에 대한 해결책은 더 많은 데이터를 모으거나 모델을 단순화하거나, 훈련데이터의 noise를 줄이는 것 이다.\n",
    "<XGBoost에서 noise를 포함하던 말던 설명변수를 늘리는게 성능향상에 좋은가? 아니다 이것은 거의 무한에 가까운 완벽한 데이터 일때나 맞는말이다.>  \n",
    "[참고]https://datascience.stackexchange.com/questions/17364/gradient-boosting-tree-the-more-variable-the-better\n",
    "\n",
    "#### 16. 테스트 세트가 무엇이고 왜 사용해야 하나요?\n",
    "- 테스트세트는 실전에 배치되기 전에 모델이 새로운 샘플에 대해 만들 일반화 오차를 추정하기 위해 사용\n",
    "\n",
    "#### 17. 검증 세트의 목적은 무엇인가요?\n",
    "- 검증 세트는 모델을 비교하는데 사용된다. 이를 사용해 가장 좋은 모델을 고르고 하이퍼파라미터를 튜닝한다.\n",
    "\n",
    "#### 18. 테스트 세트를 사용해 하이퍼파라미터를 튜닝하면 어떤 문제가 생기나요?\n",
    "- 테스트 세트에 과적합이 될 위험이 있고 일반화 오차는 매우 낙관적으로 측정될 것이다.\n",
    "\n",
    "#### 19. 교차 검증이 무엇이고, 왜 하나의 검증 세트보다 선호하나요?\n",
    "- 교차 검증은 검증 세트를 별도로 분리하지 않고 모델을 비교 할 수 있는 기술이다 ( 모델 선택과 하이퍼파라미터 튜닝을 위해 사용)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
