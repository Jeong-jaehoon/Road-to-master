{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1장 한눈에 보는 머신러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 준지도학습\n",
    "ex) 구글 포토 호스팅 서비스  \n",
    "소수의 레이블로 편리하게 사진을 찾을 수 있음  \n",
    "대부분의 준지도 학습 알고리즘은 지도 학습과 비지도 학습의 조화로 이루어져 있다.  \n",
    "`심층 신뢰 신경망` - DBN(deep belief network)는 여러 겹으로 쌓은 `제한된 볼츠만 머신` - RBM(Restricted Boltzmann machine)이라고 불리는 비지도 학습에 기초한다  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 강화학습\n",
    "강화학습은 다른 알고리즘들과는 매우 다른 종류의 알고리즘이다. 여기서 학습 하는 시스템을 `에이전트`라고 부르며 `환경`을 관찰해서 `행동`을 실행하고 그 결과로 `보상`과 `벌점`을 받는다. 시간이 지나면서 가장 큰 `보상`을 얻기 위해 `정책(policy)`라고 부르는 최상의 전략을 스스로 학습한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배치 학습(batch learning)\n",
    "\n",
    "배치 학습에서는 시스템이 점진적으로 학습할 수 없습니다. 가용한 데이터를 모두 사용해 훈련시켜야 합니다. 일반적으로 이 방식은 시간과 자원을 많이 소모하므로 보통 오프라인에서 수행된다. 먼저 시스템을 훈련시키고 그런 다음 제품 시스템에 적용하면 더 이상의 학습은 없습니다. 이를 `오프라인 학습`이라고 불립니다.  \n",
    "\n",
    "- 느낌 : 항상 전체 데이터로 학습하기 때문에 학습 시간, 비용이 많이 소요된다. 즉 많은 컴퓨팅 자원이 필요하다.  \n",
    "- 시스템이 빠르게 변하는 데이터(주식)에는 더 능동적인 방법이 필요하다\n",
    "- 즉 점진적으로 학습 할 수 있는 알고리즘이 필요하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 온라인 학습(점진적 학습)\n",
    "`온라인 학습`에서는 데이터를 순차적으로 한 개씩 또는 `미니배치`라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련시킨다. 매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는대로 즉시 학습할 수 있다.\n",
    "- 온라인 학습은 연속적으로 데이터를 받고(주식) 빠른 변화에 스스로 적응해야하는 시스템에 적합하다.\n",
    "- 컴퓨팅 자원이 제한된 경우에도 좋은 선택이다\n",
    "- 온라인 학습 시스템이 새로운 데이터 샘플을 학습하면 학습이 끝난 데이터는 더 이상 필요하지 않으므로 버려도된다.(예외적으로 데이터 재사용을 위해 필요하면 보관이 필요..) -> 공간 절약 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 온라인 학습 시스템에서 파라미터\n",
    "- 학습률을 높게하면 시스템이 데이터에 빠르게 적응하지만 예전 데이터를 금방 잊어버림\n",
    "- 학습률이 낮으면 시스템의 관성이 더커져 더 느리게 학습된다 대신 새로운 데이터에 있는 노이즈나 대표성이 없는 데이터 포인트에 덜 민감해진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사례 기반 학습과 모델 기반 학습\n",
    "`머신러닝 시스템은 어떻게 일반화 하냐에 따라 분류할 수도 있다. 대부분의 머신러닝 작업은 예측을 만드는 것인데 이 말은 주어진 훈련 데이터로 학습하지만 훈련데이터에서는 본적 없는 새로운 데이터로 일반화 되어야 한다는 뜻이다. 훈련데이터에서 높은 성능을 내는 것이 좋지만 그게 전부는 아니다. 진짜 목표는 새로운샘플(test data)에서 잘 작동하는 모델이어야한다는 것이다. 이 두가지 접근법은 사례기반학습과 모델기반 학습이다.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사례기반학습 - 50p 그림참조\n",
    "스펨매일과 동일한 메일을 스팸이라고 하는 대신 스팸 메일과 매우 유사한 메일을 구분하도록 프로그래밍이가능하다.  \n",
    "이렇게 하려면 `유사도(similarity)`를 측정하면 된다. 이를 `사례 기반 학습(instance-based learning)`이라고 한다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델기반학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플로부터 일반화시키는 다른 방법은 이 샘플들의 모델을 만들어 `예측`에 사용하는 것 입니다.  \n",
    "이 방법이 바로 `모델기반학습(model-based learning)`  \n",
    "모델을 만들려면 파라미터를 지정해줘야하는데 모델이 최상의 성능을 내도록 하는 값을 어떻게 알 수 있을까..?  이 질문에 대답하려면 측정지표를 정해야한다. 모델이 얼마나 좋은지 측정하는 `효용함수(utility function)`을 정의하거나 얼마나 나쁜지 측정하는 `비용함수(cost function)`을 정의하면 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝의 주요 도전 과제\n",
    "\n",
    "### 1. 충분하지 않은 양의 훈련 데이터\n",
    "대부분의 머신러닝 알고리즘이 작동하려면 수천에서 많게는 수백만 이상의 데이터가 필요하다.  \n",
    "2001년 논문에 따르면 데이터가 좋다면 어떠한 문제에 대해서 여러 다른 알고리즘이 문제를 비슷하게 잘 처리한다고 한다.  \n",
    "즉, 알고리즘 개발과, 좋은 말뭉치(corpus) 개발(데이터 개발)에 트레이드 오프가 필요하다는 것이다.  \n",
    "데이터를 수집하는건 항상 쉽거나 저렴한 일이 아니므로 아직은 알고리즘을 무시하지는 말아야한다.  \n",
    "\n",
    "### 2. 대표성이 없는 훈련 데이터\n",
    "일반화가 잘되려면 우리가 일반화 하기 원하는 새로운 사례를 훈련 데이터가 잘 대표하는 것이 중요하다. 이는 사례기반학습이나 모델기반학습 모두 동일하다.  \n",
    "일반화하려는 사례들을 대표하는 훈련세트를 사용하는 것이 매우 중요하지만, 쉽게 되지않는다.  \n",
    "샘플이 작으면 샘플링 잡음(sampling noise), 매우 큰 샘플도 표본 추출 방법이 잘못되면 대표성을 띄지 못할 수도 있다. 이를 샘플링 편향(Sampling bias)라고한다.  \n",
    "\n",
    "### 3. 낮은 품질의 데이터\n",
    "훈련 데이터가 에러, 이상치, 잡음으로 가득하다면 머신러닝 시스템이 내재된 패턴을 찾기 어려워 잘 작동하지 않을 것이다. 그렇기 때문에 훈련데이터 정제에 시간을 많이 투자할 필요가있다. \n",
    "\n",
    "### 4. 관련 없는 특성\n",
    "feature engineering에 대한 내용이며 feature engineering은 다음과 같은 작업을 포함한다.\n",
    "- feature selection\n",
    "- feature extraction : 특성을 결합하여 더 유용한 특성을 만든다 ( 예를 들면 차원 축소 알고리즘)\n",
    "- 새로운 데이터를 수집해 새 특성을 만듭니다.\n",
    "\n",
    "### 5. 훈련 데이터 과대적합(Overfitting)\n",
    "과대 적합은 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 일어난다. 해결방법은 다음과 같다\n",
    "- 파라미터 수가 적은 모델을 선택하거나(예를들면 고차원 다항 모델보다 선형모델), 훈련데이터에 있는 특성 수를 줄이거나, 모델에 제약을 가하여 단순화)\n",
    "- 훈련데이터를 더 많이 모은다.\n",
    "- 훈련 데이터의 잡음을 줄인다(예를들면 오류데이터 수정과 이상치 제거)   \n",
    "\n",
    "모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는것을 규제(regularization)이라고 한다. \n",
    "\n",
    "### 6.훈련 데이터 과소적합(Underfitting)\n",
    "모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 일어난다.  예를 들어 삶의 만족도에 대한 선형 모델은 과소적합 되기 쉽다. 이 문제를 해결하려면\n",
    "- 모델 파라미터가 더 많은 강력한 모델을 선택\n",
    "- 학습 알고리즘에 더 좋은 특성을 제공한다(특성 공학)\n",
    "- 모델의 제약을 줄인다(규제 파라미터(regularization parameter)를 감소)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트와 검증\n",
    "새로운 샘플에 대한 오류비율을 일반화오차(generalization error) \n",
    "훈련 오차가 낮지만 일반화 오차가 높다면 이는 모델이 훈련 데이터에 과대적합 됐다는 뜻..\n",
    "보통 80%의 train set, 20% test set 으로 데이터 나눔  \n",
    "일반화 오차를 테스트 세트에서 여러 번 측정했으므로 모델과 하이퍼파라미터가 테스트세트에 최적화된 모델을 만들 수 있음  \n",
    "이문제에 대한 해결 방법으로 `Validation set(검증 세트)`라고 부르는 홀드아웃 세트를 만드는 것이 있다.\n",
    "훈련 데이터에서 검증 세트로 너무 많은 양의 데이터를 뻇기지 않기 위해 일반적으로는 `교차 검증(Cross validation)`기법을 사용 훈련 세트를 서브셋의 조합으로 훈련시키고 나머지 부분으로 검증한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
