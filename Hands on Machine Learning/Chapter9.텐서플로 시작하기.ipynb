{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Chapter9.텐서플로 시작하기.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_GBqYOivs82",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "40aaf8e5-0c63-4e6d-9627-8bb379b3faef"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu5qrF3NoYmZ",
        "colab_type": "text"
      },
      "source": [
        "# 9장 텐서플로 시작하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x3C0jJ6v_Pb",
        "colab_type": "text"
      },
      "source": [
        "__tensorflow 2.0이 나오면서 상당히 많은 부분이 수정 되었기 때문에 텐서플로우의 전체적인 개념과 구조를 익힌다는 느낌으로 학습할 것__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mX3oyKloYma",
        "colab_type": "text"
      },
      "source": [
        "__텐서플로__ 는 수치 계산을 위한 오픈소스 소프트웨어 라이브러리로 대규모 머신러닝에 맞춰 튜닝되어있다.  \n",
        "먼저 파이썬으로 수행할 계산 그래프를 정의한다음 텐서플로가 최적화된 C++코드를 사용해 이 그래프를 효율적으로 실행시킨다.  \n",
        "무엇보다도 계산 그래프를 여러 부분으로 나누어 여러 CPU나 GPU에서 병렬로 실행할 수 있다.  \n",
        "텐서플로는 분산 컴퓨팅도 지원하므로 수백대의 서버에 계산을 나누어 납득할만한 시간안에 대규모 데이터셋으로 거대한 신경망을 훈련시킬 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zKbL8A1oYmb",
        "colab_type": "text"
      },
      "source": [
        "## 9.1 설치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW3-2fCnoYmc",
        "colab_type": "text"
      },
      "source": [
        "## 9.2 첫 번째 계산 그래프를 만들어 세션에서 실행하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBR4YmOPoYmd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a4891121-a0ea-41c6-dfe2-0ed0d2883887"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq-O7HBXoYmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.Variable(3, name=\"x\")\n",
        "y = tf.Variable(4, name=\"y\")\n",
        "f = x*x*y + y + 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCMy0kUMoYmo",
        "colab_type": "text"
      },
      "source": [
        "마지막 줄에서 뭔가 계산이 실행될것 같지만 실제로는 계산이 실행되지않는다. 단지 계산 그래프만 만들어 질 뿐이다. 이 계산 그래프를 평가하려면 텐서플로 세션을 시작하고 변수를 초기화 한 다음 f를 평가해야 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "IPGulDUdoYmp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f1c886fb-7495-4cbd-c202-db046406a5b8"
      },
      "source": [
        "sess = tf.Session()\n",
        "sess.run(x.initializer)\n",
        "sess.run(y.initializer)\n",
        "result = sess.run(f)\n",
        "print(result)\n",
        "sess.close()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSLFxZUoYmt",
        "colab_type": "text"
      },
      "source": [
        "위와 같이 계산 그래프를 만들어서 세션을 시작하고 닫아 주는 과정이 필요하다.  \n",
        "매번 sess.run()을 하면 번거로운데 다음과 같은 방법을 사용하면 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EcCjgRFoYmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    x.initializer.run()\n",
        "    y.initializer.run()\n",
        "    result = f.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8zT1GN5oYmy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a0f35100-3ea8-47ed-84da-86687f28b5d7"
      },
      "source": [
        "result"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_DbdqaNoYm5",
        "colab_type": "text"
      },
      "source": [
        "with 블록 안에서는 with 문에서 선언한 세션이 기본 세션으로 지정된다.  \n",
        "x.initializer.run()을 호출 하는것은 tf.get_default_session().run(x.initializer)를 호출하는 것과 같고,  \n",
        "y.initializer.run()을 호출 하는 것은 tf.get_default_session().run(y.initializer)를 호출하는 것과 같다.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHoB8xTDoYm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()#init 노드 준비\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    result = f.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwyzF5IgoYm_",
        "colab_type": "text"
      },
      "source": [
        "각 변수의 초기화를 일일이 실행하는 대신 global_variables_initializer() 함수를 사용할 수 있다.  \n",
        "이 함수는 초기화를 바로 수행하지 않고 계산 그래프가 실행될 때 모든 변수를 초기화할 노드를 생성한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3RvaJtRoYnA",
        "colab_type": "text"
      },
      "source": [
        "주피터나 파이썬 셀에서는 Interactivesession을 만드는 편이 편리 할 수 있다.  \n",
        "일반적인 Session과 다른점은 InteractiveSession이 만들어질때 자동으로 자신을 기본 세션으로 지정한다는 점이다. 그러므로 with 블록을 생성할 필요는 없다(하지만 수동으로 세션 종료해주어야함)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMM5COy8oYnB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b7d34533-4dd0-4533-fc17-cac7a7cb8eaa"
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "init.run()\n",
        "result = f.eval()\n",
        "print(result)\n",
        "sess.close()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuRxUeEVoYnF",
        "colab_type": "text"
      },
      "source": [
        "_일반적으로 텐서플로 프로그램은 두 부분으로 나뉜다_   \n",
        "첫 부분은 계산그래프를 만들고(__구성단계__)  \n",
        "두 번쨰 부분은 이 그래프를 실행하는 것(__실행단계__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0MoyF9UoYnF",
        "colab_type": "text"
      },
      "source": [
        "## 9.3 계산 그래프 관리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLtwkwsLoYnG",
        "colab_type": "text"
      },
      "source": [
        "노드를 만들면 자동으로 기본 계산 그래프에 추가된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt2LNhfQoYnH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bc8fab59-23db-4986-c9e1-484f564aeda3"
      },
      "source": [
        "x1 = tf.Variable(1)\n",
        "x1.graph is tf.get_default_graph()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAHQUBGcoYnL",
        "colab_type": "text"
      },
      "source": [
        "대부분의 경우 이것으로 충분하지만 가끔은 독립적인 계산 그래프를 여러개 만들어야 할 때가 있다 .  \n",
        "이렇게 하려면 다음과 같이 새로운 Graph 객체를 만들어 with 블록 안에서 임시로 이를 기본 계산 그래프로 사용할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaKY5Gj0oYnN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "060f27d1-67c0-43aa-b433-975b2e48ff92"
      },
      "source": [
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "    x2 = tf.Variable(2)\n",
        "    \n",
        "x2.graph is graph"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PelOutrUoYnS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "73614a07-de54-4443-85f4-ec4f014b4813"
      },
      "source": [
        "x2.graph is tf.get_default_graph()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_b1QjYQoYnW",
        "colab_type": "text"
      },
      "source": [
        "## 9.4 노드값의 생애 주기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHy_wo3voYnX",
        "colab_type": "text"
      },
      "source": [
        "한 노드를 평가할 때 텐서플로는 이 노드가 의존하고 있는 다른 노드들을 찾아 먼저 평가한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqRGakWNoYnX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "33c9c762-81f5-45e6-8221-6cc2b398183b"
      },
      "source": [
        "w = tf.constant(3)\n",
        "x = w + 2\n",
        "y = x + 5\n",
        "z = x * 3\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print(y.eval())\n",
        "    print(z.eval())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX-cNA2ZoYnc",
        "colab_type": "text"
      },
      "source": [
        "위 코드를 뜯어보면,  \n",
        "먼저 매우 간단한 그래프를 정의하고 있고, 그 다음 세션을 시작하고 y를 평가 하기위해 계산 그래프를 실행한다.  \n",
        "텐서플로는 자동으로 y가 x에 의존한다는 것과 x가 w에 의존한다는 것을 감지하고 있다.  \n",
        "그래서 먼저 w를 평가하고 그다음에 x를 그다음에 y를 평가해서 y를 반환하는 구조이다.  \n",
        "중요한점은 이전에 평가된  w와 x를 재사용하지 않는다는 것이다.  \n",
        "요약하면 위 코드는 w와  x를 두 번 평가한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9tYinqPoYnc",
        "colab_type": "text"
      },
      "source": [
        "이전 코드처럼 w와 x를 두 번 평가하지 않고 y와 z를 효율적으로 평가하려면 텐서플로가 한 번의 그래프 실행에서 y와 z를 모두 평가하도록 만들어야 한다.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeykr58qoYnd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a08fa1c3-58cf-4c50-fbab-9d337c87c1fb"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    y_val, z_val = sess.run([y,z])\n",
        "    print(y_val)\n",
        "    print(z_val)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDtUlEHBoYnj",
        "colab_type": "text"
      },
      "source": [
        "## 9.5 텐서플로를 이용한 선형 회귀"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz86TPknoYnk",
        "colab_type": "text"
      },
      "source": [
        "텐서플로 연산은 여러개의 입력을 받아 출력을 만들 수 있다. \n",
        "상수와 변수 연산은 입력이 없고, 입력과 출력은 __텐서__라는 다차원 배열이다.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubqSiV4QoYnl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "d3e3ccff-3292-488f-a7a8-17c7bf1d35e9"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "m, n = housing.data.shape\n",
        "housing_data_plus_bias = np.c_[np.ones((m,1)), housing.data]\n",
        "\n",
        "X = tf.constant(housing_data_plus_bias, dtype = tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32, name = \"y\")\n",
        "XT = tf.transpose(X)\n",
        "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)), XT), y) #점곱\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    theta_value = theta.eval()\n",
        "print(theta_value)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[-3.67372932e+01]\n",
            " [ 4.37366009e-01]\n",
            " [ 9.47520509e-03]\n",
            " [-1.08159676e-01]\n",
            " [ 6.48537397e-01]\n",
            " [-3.84734449e-06]\n",
            " [-3.79239232e-03]\n",
            " [-4.19136107e-01]\n",
            " [-4.32144403e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHD-Abv9oYnp",
        "colab_type": "text"
      },
      "source": [
        "## 9.6 경사 하강법 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Eu-N0DDoYnq",
        "colab_type": "text"
      },
      "source": [
        "### 9.6.1 직접 경사하강법 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yIobrgPoYnr",
        "colab_type": "text"
      },
      "source": [
        "정규방정식 대신 __경사하강법__을 사용.  \n",
        "경사하강법을 사용할때는 입력 특성 벡터를 정규화 해야한다. 그렇지 않으면 훈련 속도가 현저히 느려진다.  \n",
        "이 코드에서는 이미 정규화 되어있다고 가정하고 진행 하도록 함."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-Kig5MvoYns",
        "colab_type": "text"
      },
      "source": [
        "- random_uniform() 하수는 난수를 담은 텐서를 생성하는 노드를 그래프에 생성한다. 넘파이의 rand() 함수처럼 크기와 난수의 범위를 입력받습니다.\n",
        "- assign() 함수는 변수에 새로운 값을 할당하는 노드를 생성한다. 여기서는 배치 경사 하강법의 스텝을 구현한다.\n",
        "- 반복루프는 훈련 단계를 반복해서 실행하고(n_epoch만큼) 100번 반복마다 현재의 mse를 출력한다. mse는 매 반복에서 줄어야한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbvRqMgUoYnt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB7I0oCtoYny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuHB_fjcoYn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp = scaler.fit_transform(housing_data_plus_bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKiB6j_roYn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaled_housing_data_plus_bias = temp.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "zsMOCwf3oYn-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "40c0e50c-96c8-481f-ae8b-fd6e291b443c"
      },
      "source": [
        "type(scaled_housing_data_plus_bias)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICRpxsfWoYoD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "4003ee68-51ee-47ba-8db3-0f2e6dd02237"
      },
      "source": [
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name='y')\n",
        "theta = tf.Variable(tf.random_uniform([n+1,1], -1.0, 1.0), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
        "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
        "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        if epoch % 100 ==0:\n",
        "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
        "        sess.run(training_op)\n",
        "    \n",
        "    best_tehta = theta.eval()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 MSE = 9.934187\n",
            "Epoch 100 MSE = 4.905781\n",
            "Epoch 200 MSE = 4.8447256\n",
            "Epoch 300 MSE = 4.8337193\n",
            "Epoch 400 MSE = 4.826181\n",
            "Epoch 500 MSE = 4.8205967\n",
            "Epoch 600 MSE = 4.816436\n",
            "Epoch 700 MSE = 4.813322\n",
            "Epoch 800 MSE = 4.810983\n",
            "Epoch 900 MSE = 4.8092184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um8LDp-YoYoI",
        "colab_type": "text"
      },
      "source": [
        "### 9.6.2 자동 미분 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX8a3ItvoYoI",
        "colab_type": "text"
      },
      "source": [
        "tf.gradients()  \n",
        "를 통해 텐서플로우로 자동미분이 가능하다\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qxb6BcVVoYoJ",
        "colab_type": "text"
      },
      "source": [
        "텐서플로우는 __후진 모드 자동 미분(reverse-mode autodiff)__를 사용한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gepS9q88oYoJ",
        "colab_type": "text"
      },
      "source": [
        "### 9.6.3 옵티마이저 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHuE7qyUoYoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
        "training_op = optimizer.minimize(mse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_uaTCOToYoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.train.MomentumOptimizer(learning_rate = learning_rate,\n",
        "                                      momentum = 0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as_Q6xVyoYoV",
        "colab_type": "text"
      },
      "source": [
        "## 9.7 훈련 알고리즘에 데이터 주입"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrknCkCroYoW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6d2c70e9-ed9c-407a-ea47-5fd6cf8de0ac"
      },
      "source": [
        "A = tf.placeholder(tf.float32, shape = (None, 3))\n",
        "B = A + 5\n",
        "with tf.Session() as sess:\n",
        "    B_val_1 = B.eval(feed_dict={A: [[1,2,3]]})\n",
        "    B_val_2 = B.eval(feed_dict={A: [[4,5,6],[7,8,9]]})\n",
        "    \n",
        "print(B_val_1)\n",
        "print(B_val_2)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6. 7. 8.]]\n",
            "[[ 9. 10. 11.]\n",
            " [12. 13. 14.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIO9IguxoYoZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 1000\n",
        "learning_rate = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Eq5-3EMoYoc",
        "colab_type": "text"
      },
      "source": [
        "### 미니배치 경사하강법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFt6oGppoYoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
        "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdhRSB33oYog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(mse)\n",
        "\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwvJqZR-oYok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfK7LFaCoYon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "n_batches = int(np.ceil(m / batch_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "242GDsDUoYor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fetch_batch(epoch, batch_index, batch_size):\n",
        "    np.random.seed(epoch * n_batches + batch_index)  # not shown in the book\n",
        "    indices = np.random.randint(m, size=batch_size)  # not shown\n",
        "    X_batch = scaled_housing_data_plus_bias[indices] # not shown\n",
        "    y_batch = housing.target.reshape(-1, 1)[indices] # not shown\n",
        "    return X_batch, y_batch\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for batch_index in range(n_batches):\n",
        "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "\n",
        "    best_theta = theta.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6RVUtbdoYov",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "f138d738-ad98-42aa-9d7b-deeb0c374fc7"
      },
      "source": [
        "best_theta"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.9045429 ],\n",
              "       [ 0.8217246 ],\n",
              "       [ 0.11330824],\n",
              "       [-0.21355599],\n",
              "       [ 0.32225582],\n",
              "       [-0.00730818],\n",
              "       [ 0.00515021],\n",
              "       [-0.8838435 ],\n",
              "       [-0.856859  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTbeHHKdoYo0",
        "colab_type": "text"
      },
      "source": [
        "## 9.8 모델의 저장과 복원"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvXD7M3PoYo0",
        "colab_type": "text"
      },
      "source": [
        "텐서플로우에서 모델의 저장은 매우 쉽다.  \n",
        "구성 단계의 끝에서 __Saver 노드를 추가하고, 실행 단계에서 모델을 저장 하고 싶을 때 save() 메서드에 세션과 체크포인트 파일의 경로를 전달하여 호출하면 된다.__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGnYZvl3oYo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpCksmS4oYpB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "36e6f49d-933b-4791-902d-ae751fd6984a"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "n_epochs = 1000                                                                       # 책에는 없습니다.\n",
        "learning_rate = 0.01                                                                  # 책에는 없습니다.\n",
        "\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")            # 책에는 없습니다.\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")            # 책에는 없습니다.\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")                                      # 책에는 없습니다.\n",
        "error = y_pred - y                                                                    # 책에는 없습니다.\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")                                    # 책에는 없습니다.\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)            # 책에는 없습니다.\n",
        "training_op = optimizer.minimize(mse)                                                 # 책에는 없습니다.\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        if epoch % 100 == 0:\n",
        "            print(\"에포크\", epoch, \"MSE =\", mse.eval())                                # 책에는 없습니다.\n",
        "            save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\n",
        "        sess.run(training_op)\n",
        "    \n",
        "    best_theta = theta.eval()\n",
        "    save_path = saver.save(sess, \"/tmp/my_model_final.ckpt\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "에포크 0 MSE = 8.44099\n",
            "에포크 100 MSE = 4.905503\n",
            "에포크 200 MSE = 4.844091\n",
            "에포크 300 MSE = 4.8344774\n",
            "에포크 400 MSE = 4.827744\n",
            "에포크 500 MSE = 4.8225694\n",
            "에포크 600 MSE = 4.818562\n",
            "에포크 700 MSE = 4.8154416\n",
            "에포크 800 MSE = 4.813001\n",
            "에포크 900 MSE = 4.8110805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzSAp7QEoYpG",
        "colab_type": "text"
      },
      "source": [
        "## 9.9 텐서보드로 그래프와 학습 곡선 시각화하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AADqDO-QoYpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# This module defines the show_graph() function to visualize a TensorFlow graph within Jupyter.\n",
        "\n",
        "# As far as I can tell, this code was originally written by Alex Mordvintsev at:\n",
        "# https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb\n",
        "\n",
        "# The original code only worked on Chrome (because of the use of <link rel=\"import\"...>, but the version below\n",
        "# uses Polyfill (copied from this StackOverflow answer: https://stackoverflow.com/a/41463991/38626)\n",
        "# so that it can work on other browsers as well.\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from IPython.display import clear_output, Image, display, HTML\n",
        "\n",
        "def strip_consts(graph_def, max_const_size=32):\n",
        "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
        "    strip_def = tf.GraphDef()\n",
        "    for n0 in graph_def.node:\n",
        "        n = strip_def.node.add() \n",
        "        n.MergeFrom(n0)\n",
        "        if n.op == 'Const':\n",
        "            tensor = n.attr['value'].tensor\n",
        "            size = len(tensor.tensor_content)\n",
        "            if size > max_const_size:\n",
        "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
        "    return strip_def\n",
        "\n",
        "def show_graph(graph_def, max_const_size=32):\n",
        "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
        "    if hasattr(graph_def, 'as_graph_def'):\n",
        "        graph_def = graph_def.as_graph_def()\n",
        "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
        "    code = \"\"\"\n",
        "        <script src=\"//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js\"></script>\n",
        "        <script>\n",
        "          function load() {{\n",
        "            document.getElementById(\"{id}\").pbtxt = {data};\n",
        "          }}\n",
        "        </script>\n",
        "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
        "        <div style=\"height:600px\">\n",
        "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
        "        </div>\n",
        "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
        "\n",
        "    iframe = \"\"\"\n",
        "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
        "    \"\"\".format(code.replace('\"', '&quot;'))\n",
        "    display(HTML(iframe))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV_HKdReoYpM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "57ec7c61-0443-49bb-d610-f0128fd6ecce"
      },
      "source": [
        "show_graph(tf.get_default_graph())"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
              "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
              "        <script>\n",
              "          function load() {\n",
              "            document.getElementById(&quot;graph0.1784179106002547&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 9\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\t\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;random_uniform/max&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_uniform/RandomUniform&quot;\\n  input: &quot;random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_uniform/mul&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 9\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;theta&quot;\\n  input: &quot;random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;theta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;predictions&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;theta/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;predictions&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mse&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Square&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/grad_ys_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/grad_ys_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/mse_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/mse_grad/Reshape&quot;\\n  input: &quot;gradients/mse_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/mse_grad/Shape_1&quot;\\n  input: &quot;gradients/mse_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/mse_grad/Shape_2&quot;\\n  input: &quot;gradients/mse_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/mse_grad/Prod_1&quot;\\n  input: &quot;gradients/mse_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/mse_grad/Prod&quot;\\n  input: &quot;gradients/mse_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/mse_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/mse_grad/Tile&quot;\\n  input: &quot;gradients/mse_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/mse_grad/truediv&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;sub&quot;\\n  input: &quot;gradients/Square_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/mse_grad/truediv&quot;\\n  input: &quot;gradients/Square_grad/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;predictions&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/sub_grad/Shape&quot;\\n  input: &quot;gradients/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Square_grad/Mul_1&quot;\\n  input: &quot;gradients/sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sub_grad/Sum&quot;\\n  input: &quot;gradients/sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients/Square_grad/Mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/sub_grad/Neg&quot;\\n  input: &quot;gradients/sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sub_grad/Sum_1&quot;\\n  input: &quot;gradients/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sub_grad/Reshape_1&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;theta/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/predictions_grad/MatMul&quot;\\n  input: &quot;^gradients/predictions_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/predictions_grad/MatMul&quot;\\n  input: &quot;^gradients/predictions_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/predictions_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/predictions_grad/MatMul_1&quot;\\n  input: &quot;^gradients/predictions_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/predictions_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_theta/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;theta&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/predictions_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent/update_theta/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^theta/Assign&quot;\\n}\\nnode {\\n  name: &quot;MSE_1/tags&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;MSE_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MSE_1&quot;\\n  op: &quot;ScalarSummary&quot;\\n  input: &quot;MSE_1/tags&quot;\\n  input: &quot;mse&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;predictions&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;loss/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/mse&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/Square&quot;\\n  input: &quot;loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\n';\n",
              "          }\n",
              "        </script>\n",
              "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
              "        <div style=&quot;height:600px&quot;>\n",
              "          <tf-graph-basic id=&quot;graph0.1784179106002547&quot;></tf-graph-basic>\n",
              "        </div>\n",
              "    \"></iframe>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WpFd0s-oYpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "root_logdir = \"tf_logs\"\n",
        "logdir = \"{}/run-{}/\".format(root_logdir, now)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhHotf66oYpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
        "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(mse)\n",
        "\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDM0ddvaoYpb",
        "colab_type": "text"
      },
      "source": [
        "#### 텐서보드가 인식하게 하기위한 summary 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y3X-dw6oYpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mse_summary = tf.summary.scalar('MSE', mse)\n",
        "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-uva382oYpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 10\n",
        "batch_size = 100\n",
        "n_batches = int(np.ceil(m / batch_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNPovBNDoYpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:                                                        \n",
        "    sess.run(init)                                                                \n",
        "\n",
        "    for epoch in range(n_epochs):                                                 \n",
        "        for batch_index in range(n_batches):\n",
        "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
        "            if batch_index % 10 == 0:\n",
        "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "                step = epoch * n_batches + batch_index\n",
        "                file_writer.add_summary(summary_str, step)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "\n",
        "    best_theta = theta.eval()          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pptfPgsfoYpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHpZp_dVoYpu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "88928647-6c15-4ad6-fd35-b507bc79e327"
      },
      "source": [
        "best_theta"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.1673944 ],\n",
              "       [ 0.8651597 ],\n",
              "       [ 0.11857294],\n",
              "       [-0.29859856],\n",
              "       [ 0.3962899 ],\n",
              "       [-0.00649125],\n",
              "       [ 0.00409025],\n",
              "       [-0.8007695 ],\n",
              "       [-0.7800272 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYjhaFmdoYp0",
        "colab_type": "text"
      },
      "source": [
        "## 9.10 이름범위"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XID3nPa3oYp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope(\"loss\") as scope:\n",
        "    error = y_pred - y\n",
        "    mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24ODvDMIoYp4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "06ec5e9f-180c-4126-bb40-2cd23651cffa"
      },
      "source": [
        "print(error.op.name)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss/sub\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXshDIz1oYp7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "29b1a69d-1368-42d9-f67c-4415735cbe03"
      },
      "source": [
        "print(mse.op.name)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss/mse\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU_tbXQLoYp-",
        "colab_type": "text"
      },
      "source": [
        "이름범위를 쓰는 이유 => 신경망처럼 매우 복잡한 모델을 다룰 떄는 게산 그래프가 수천 개의 노드로 인해 어질러지기 쉬워 __이름범위(name space)__ 를 만들어 관련있는 노드를 그룹으로 묶어야한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8igqWQ0oYp-",
        "colab_type": "text"
      },
      "source": [
        "## 9.11 모듈화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxojIrpDoYp_",
        "colab_type": "text"
      },
      "source": [
        "아래와 같은 반복적인코드,  \n",
        "복사 붙여넣기를 이용한 코드는 실수가 많을 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lnGeZlSoYp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "n_features = 3\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
        "\n",
        "w1 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights1\")\n",
        "w2 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights2\")\n",
        "b1 = tf.Variable(0.0, name=\"bias1\")\n",
        "b2 = tf.Variable(0.0, name=\"bias2\")\n",
        "\n",
        "z1 = tf.add(tf.matmul(X, w1), b1, name=\"z1\")\n",
        "z2 = tf.add(tf.matmul(X, w2), b2, name=\"z2\")\n",
        "\n",
        "relu1 = tf.maximum(z1, 0., name=\"relu1\")\n",
        "relu2 = tf.maximum(z1, 0., name=\"relu2\")  # Oops, cut&paste error! Did you spot it?\n",
        "\n",
        "output = tf.add(relu1, relu2, name=\"output\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIYE-91xoYqD",
        "colab_type": "text"
      },
      "source": [
        "아래와 같이 변경해보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhxRD9t-oYqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "def relu(X):\n",
        "    w_shape = (int(X.get_shape()[1]), 1)\n",
        "    w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
        "    b = tf.Variable(0.0, name=\"bias\")\n",
        "    z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
        "    return tf.maximum(z, 0., name=\"relu\")\n",
        "\n",
        "n_features = 3\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
        "relus = [relu(X) for i in range(5)]\n",
        "output = tf.add_n(relus, name=\"output\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ357UJxoYqI",
        "colab_type": "text"
      },
      "source": [
        "## 9.12 변수공유"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44_WKO0goYqJ",
        "colab_type": "text"
      },
      "source": [
        "그래프의 여러구성요소들 간에 변수를 공유하고 싶다면 변수를 먼저 만들어 매개변수 형식으로 전달하는 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp_mxzXEoYqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "def relu(X, threshold):\n",
        "    with tf.name_scope(\"relu\"):\n",
        "        w_shape = (int(X.get_shape()[1]), 1)                        \n",
        "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  \n",
        "        b = tf.Variable(0.0, name=\"bias\")                           \n",
        "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                    \n",
        "        return tf.maximum(z, threshold, name=\"max\")\n",
        "\n",
        "threshold = tf.Variable(0.0, name=\"threshold\")\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
        "relus = [relu(X, threshold) for i in range(5)]\n",
        "output = tf.add_n(relus, name=\"output\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GEWSv4FDTPn",
        "colab_type": "text"
      },
      "source": [
        "## 9.13 연습문제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g5nd0qlDYPW",
        "colab_type": "text"
      },
      "source": [
        "1. 계산을 직접 실행하지 않고 계산 그래프를 만드는 주요 장점과 단점은 무엇인가?\n",
        "\n",
        "장점\n",
        "- 텐서플로가 자동으로 그래디언트를 계산할 수 있다.\n",
        "- 테너플로가 여러 스레드에서 연산을 병렬로 실행할 수 있다.\n",
        "- 동일한 모델을 여러 장치에 걸쳐 실행시키기 편리하다.\n",
        "- 내부 구조를 살피기 쉽다.\n",
        "\n",
        "단점\n",
        "- 익숙하게 다루려면 시간이 필요하다.\n",
        "- 단계별 디버깅을 수행하기 어렵다.\n",
        "\n",
        "2. a_val = a.eval(session = sess)와 a_val = sess.run(a)는 동일한 문장인가? - 예\n",
        "3. a_val, b_val = a.eval(session = sess), b.eval(session = sess)와 a_val, b_val = sess.run([a,b])는 동일한 문장인가? - 아니요  \n",
        "\n",
        "첫번째 문장은 그래프를 두 번(한 번은 a, 또 한번은 b를 계산하기위해) 실행하지만 두 번째 문장은 그래프를 한 번만 실행한다. 이 연산이 부수효과를 일으키면 결과가 달라질 것이다. 만약 부수효과가 없다면 두 문장은 동일한 결과를 반환하지만 두 번재 문장이 첫번재 문장보다 속도가 빠를 것이다.\n",
        "\n",
        "4. 같은 세션에서 두 개의 그래프를 실핼할 수 있나?  \n",
        "\n",
        "아니오. 같은 세션에서 두 개의 그래프를 실행할 수 없습니다. 먼저 두 개의 그래프를 하나의 그래프로 합쳐야 한다.\n",
        "\n",
        "5. 만약 변수 w를 가진 그래프 g를 만들고 스레드를 두 개 시작해 각 스레드에서 동일하나 그래프 g를 사용하는 세션을 열면 각 세션은 변수 w를 따로 가지게 될까요? 아니면 공유할까요?\n",
        "\n",
        "로컬 텐서플로에서는 세션이 변숫값을 관리하므로 만약 변수 w를 가진 그래프 g를 만들고 동일한 그래프 g를 사용하는 두 개의 스레드를 시작해 각 스레드에서 로컬 세션을 열면 각 세션은 변수 w의 복사본을 각자 가지게 될것이다. 그러나 분산 텐서플로에서는 변숫값이 클러스터에 의해 관리되는 컨테이너에 저장된다. 그러므로 두 개의 세션이 같은 클러스터에 접속하여 같은 컨테이너를 사용하면 동일한 변수 w의 값을 공유할 것이다.\n",
        "\n",
        "6. 변수는 언제 초기화되고 언제 소멸되나?\n",
        "\n",
        "변수는 초기화 함수가 호출 될때 초기화 되고 세션이 종료될 때 소멸된다.\n",
        "\n",
        "7. 플레이스 홀더와 변수의 차이점은 무엇인가?\n",
        "\n",
        "변수는 값을 가진 연산이고 변수를 실행하면 값이 반환된다. 변수는 실행하기전에 초기화 해야하고 변수의 값을 바꿀 수 있다. 즉, 그래프를 연속해서 실행할 때 변수는 동일한 값을 유지한다.\n",
        "\n",
        "플레이스 홀더는 기술적으로 봤을 때 많은 일을 하지는 않는다. 표현하려는 텐서의 크기와 타입에 대한.....\n",
        "- 텐서플로 2 에서 삭제\n",
        "\n",
        "8. 플레이스 홀더에 의존하는 연산을 평가하기 위해 그래프를 실행할 때 플레이스 홀더에 값을 주입하지 않으면 어떻게 될까? 플레이스 홀더에 의존하지 않는 연산이라면 어떻게 될까?\n",
        "\n",
        "9. 그래프를 실행할 때 어떤 연산자의 출력값을 주입할 수 있나? 아니면 플레이스 홀더의 값만 가능한가?\n",
        "\n",
        "10. 변수에 원하는 값을 어떻게 설정할 수 있나요?\n",
        "\n",
        "11. 후진 모드 자동 미분으로 변수 10개에 대한 비용 함수의 그래디언트를 계산하려면 그래프를 몇번 순회해야하나? 전진모드 자동미분이나 기호 미분의 경우는 어떨까?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLzLG52JGbcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}